# -*- coding: utf-8 -*-
"""Pytorch_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-2ig_yQkXZEbrFNdyiTGmgxiI9LncI3C
"""

import  torch
print(torch.__version__)

##Creating a tensor in Pytorch using empty function
a = torch.empty(2,3)
#here we have created a tensor  a of 2,3 shape

#checking type of tensor
type(a)

#creating a tensor using zeros
torch.zeros(2,3)
#here all the vales assigned to our tensor will be zero

#creating a tensor using ones
torch.ones(2,3)
#here all the vales assigned to our tensor will be ones

#Creating a tensor of 2,3 shape having values randomly between 0 and 1
torch.rand(2,3)

"""But the problem with torch.rand(2,3) is that every time we run it we get differengt values, so to solve this problem we use seed to get same value everytime."""

#Creating a tensor using seed
torch.manual_seed(100)
torch.rand(2,3)

torch.manual_seed(100)
torch.rand(2,3)

"""Here we got same values using seed value as 100"""

#Creating our own custom tensors
torch.tensor([[1,2,3],[4,5,6]])

"""Similarly we can create using functions such as arrange, linspace(linearly spaced) , eye(identical)."""

#Creating a tensor and checking its shape

x = torch.tensor([[1,2,3],[4,5,6]])
x

x.shape

#creating a new tensor of same shape of x
y = torch.empty_like(x)
y

#Creating a new tensor like x with zeros
torch.zeros_like(x)

"""## **Tensor Data Types**

"""

#checking data type of x
x.dtype

#assign data type when creating a tensor
torch.tensor([[1.0,2.0,3.0]],dtype=torch.int32)

#converting int 32 to float
torch.tensor([[1,2,3]],dtype=torch.float64)

#changing data type using .to() function
x.to(torch.float64)

"""## **Mathematical operations on Tensors**"""

#Scaler operations

x = torch.rand(2,3)
x

#add
x + 2
print(x)

#sub
x - 2
x

#multiply
x * 2
print(x)

#divide
x / 2
print(x)

#integer division
(x*100)/3
print(x)

#mod
((x*100)/3)%2
print(x)

#power
x**2
print(x)

#Element wise operations
a = torch.rand(2,3)
b = torch.rand(2,3)
print(a)
print(b)

#add
a + b
print(a)

#sub
a - b
print(a)

#multiply
a * b
print(a)

#finding absolute value of a tensor

c = torch.tensor([1,-2,3,-4])
torch.abs(c)

#finding negative value of a tensor

c = torch.tensor([1,-2,3,-4])
torch.negative(c)

#finding round value of a tensor

c = torch.tensor([1.3,-2,3,-4])
torch.round(c)

#finding ceil value of a tensor

c = torch.tensor([1.3,-2.7,3.9,-4.5])
torch.ceil(c)

#finding floor value of a tensor

c = torch.tensor([1.3,-2.7,3.9,-4.5])
torch.floor(c)

#finding clamp value of a tensor

c = torch.tensor([1.3,-2.7,3.9,-4.5])
torch.clamp(c, min=2, max=3)

"""Reduction Operation(whole tensor to be reduced into a single number)"""

e = torch.randint(size=(2,3), low= 0, high=10,dtype=torch.float64)
f = torch.randint(size=(2,3), low= 0, high=10,dtype=torch.float64)
print(e)
print(f)

#sum
torch.sum(e)

#sum along rows
torch.sum(e, dim=0)

#sum along columns
torch.sum(e, dim=1)

#mean along row
torch.mean(e)

#mean along columns
torch.mean(e,dim=0)

#median along row
torch.median(e)

#median along columns
torch.median(e,dim=0)

#max and min value
torch.max(e)
torch.min(e)

#product of the tensors
torch.prod(e)

#standard deviation
torch.std(e)

#variance
torch.var(e)

#Argmax ( tells the position of the biggest item)
torch.argmax(e)

#Argmin (tells the position of the biggest item)
torch.argmin(e)

"""# **Matrix Operations**"""

e = torch.randint(size=(2,3), low= 0, high=10,dtype=torch.float64)
g = torch.randint(size=(3,3), low= 0, high=10,dtype=torch.float64)
print(e)
print(f)

#matrix multiplication of e and f
torch.matmul(e,g)

#dot product between 2 vectors
v1 = torch.tensor([1,2,3])
v2 = torch.tensor([4,5,6])
dot_product = torch.dot(v1,v2)
print(dot_product)

#Transpose
torch.transpose(f,0,1)

#determinant(works only on square matrix)
torch.det(g)

#inverse(works only on square matrix)
torch.inverse(g)

"""**Comparision Operations**"""

i=torch.randint(size=(2,3),low=1, high=10)
j=torch.randint(size=(2,3),low=1, high=10)

#greater
i>j

#less than
i<j

#equal to
i==j

#not equal to
i!=j

##similarly we can have (grater than equal) to and (less than equal to)

"""**Special Functions**"""

k = torch.randint(size=(2,3),low=1, high=10,dtype=torch.float32)
k

#log
torch.log(k)

#exp
torch.exp(k)

#sqrt
torch.sqrt(k)

#sigmoid
torch.sigmoid(k)

#softmax
torch.softmax(k,dim=0)

#softmax
torch.softmax(k,dim=1)

#relu
torch.relu(k)